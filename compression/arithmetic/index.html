<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>算術符号化 (Arithmetic Coding)</title>
    <link rel="stylesheet" href="./../../styles.css">
</head>
<body>
    <ul class="breadcrumb">
        <li><a href="./../../">アルゴリズムの学習</a></li>
        <li><a href="./../">圧縮・解凍問題</a></li>
        <li>算術符号化</li>
    </ul>

    <div class="container">
        <h1>算術符号化 (Arithmetic Coding)</h1>
        <div class="section">
            <h2>アルゴリズムの概要</h2>
            <p>算術符号化は、データ圧縮のためのエントロピー符号化手法の一つで、確率モデルに基づいて複数のシンボルを単一の数値（通常は0から1の間の実数）に変換することで効率的な圧縮を実現します。このアルゴリズムは、特に入力シーケンスの確率分布に大きな偏りがある場合に優れた圧縮性能を発揮します。</p>
            
            <h3>基礎知識</h3>
            <p>算術符号化は、情報理論における「エントロピー符号化」の一種です。従来のハフマン符号化などとは異なり、個々のシンボルに符号を割り当てるのではなく、入力シーケンス全体を単一の数値で表現します。この方法により、理論的には入力データのエントロピーに非常に近い圧縮率を達成することが可能になります。</p>
            <p>算術符号化の基本的な考え方は、入力シーケンスの各シンボルを処理するごとに、現在の範囲（最初は[0, 1)）を、そのシンボルの出現確率に比例した小さな範囲に狭めていくというものです。最終的に得られる範囲内の任意の数値（通常は最も短く表現できる数値）を出力として選びます。</p>
            <p>この方法は、特に適応型の確率モデルと組み合わせることで、データの局所的な特性に応じた効率的な圧縮が可能になります。また、他の符号化技術と比較して、理論的な最適性（エントロピー限界への接近）という点で優れています。</p>
            
            <h3>用語説明</h3>
            <ul>
                <li><strong>エントロピー（Entropy）</strong>: 情報の不確かさを測る指標。シンボルの出現確率に基づいて計算される</li>
                <li><strong>確率モデル（Probability Model）</strong>: 各シンボルの出現確率を定義するモデル</li>
                <li><strong>累積分布関数（Cumulative Distribution Function, CDF）</strong>: シンボルの確率を累積して計算した関数</li>
                <li><strong>符号区間（Code Interval）</strong>: 符号化過程で扱われる実数の範囲</li>
                <li><strong>下限値（Low）</strong>: 現在の符号区間の下限</li>
                <li><strong>上限値（High）</strong>: 現在の符号区間の上限</li>
                <li><strong>範囲（Range）</strong>: 上限値と下限値の差</li>
                <li><strong>スケーリング（Scaling）</strong>: 浮動小数点演算の精度問題を回避するための技術</li>
                <li><strong>適応型モデル（Adaptive Model）</strong>: データを処理しながら確率モデルを更新していく方式</li>
                <li><strong>静的モデル（Static Model）</strong>: 事前に定義された固定の確率モデル</li>
                <li><strong>アンダーフロー（Underflow）</strong>: 小さすぎる数値を扱う際に発生する計算精度の問題</li>
                <li><strong>エンコーダ（Encoder）</strong>: 元データを圧縮形式に変換する処理</li>
                <li><strong>デコーダ（Decoder）</strong>: 圧縮データを元のデータに戻す処理</li>
            </ul>
            
            <h3>特徴</h3>
            <p>算術符号化の主な特徴は以下の通りです：</p>
            <ul>
                <li>シンボル単位ではなくシーケンス全体を一つの数値として符号化する</li>
                <li>理論的にはエントロピー限界に非常に近い圧縮率を達成できる</li>
                <li>ハフマン符号化と異なり、整数ビット数に制限されない</li>
                <li>確率分布に大きな偏りがある場合に特に効果的</li>
                <li>適応型モデルと組み合わせることで、データの局所的特性に適応可能</li>
                <li>計算コストはハフマン符号化よりも高い傾向がある</li>
                <li>精度の問題を解決するためのスケーリング技術が必要</li>
                <li>特許の問題があったが、現在はほとんどの特許が期限切れ</li>
                <li>テキスト、画像、音声など様々なデータ形式に適用可能</li>
                <li>他の圧縮技術と組み合わせて使用されることが多い</li>
            </ul>
            
            <h3>適用ケース</h3>
            <p>算術符号化は以下のような場面で特に有用です：</p>
            <ul>
                <li>高い圧縮率が要求される場面（特にハフマン符号化が効率的でない場合）</li>
                <li>確率分布に大きな偏りがあるデータの圧縮</li>
                <li>画像圧縮形式（JPEG2000、JBIG、JBIG2など）</li>
                <li>ビデオ圧縮技術（H.264/AVCなど）</li>
                <li>音声圧縮（一部のコーデックで使用）</li>
                <li>テキスト圧縮（特に自然言語テキスト）</li>
                <li>医療画像のような高品質な圧縮が必要な分野</li>
                <li>確率的言語モデルと組み合わせた文書圧縮</li>
                <li>衛星データや科学データなどの大量データの効率的な保存・伝送</li>
                <li>帯域幅が制限された通信システム</li>
            </ul>
        </div>
    
        <div class="section">
            <h2>アルゴリズムの手順</h2>
            <h3>具体的な手順</h3>
            <p>算術符号化アルゴリズムは、エンコード（符号化）とデコード（復号）の2つの主要プロセスから成り立っています：</p>
            
            <h4>1. エンコード（符号化）プロセス</h4>
            <ol>
                <li>初期設定：
                    <ul>
                        <li>使用する確率モデルを決定する（静的または適応型）</li>
                        <li>区間を初期化する：下限値（low）= 0.0、上限値（high）= 1.0</li>
                        <li>各シンボルの累積確率分布を計算する</li>
                    </ul>
                </li>
                <li>入力シーケンスの処理：
                    <ul>
                        <li>入力シーケンスの各シンボルに対して：
                            <ul>
                                <li>現在の区間の範囲（range = high - low）を計算</li>
                                <li>new_high = low + range * 累積確率(シンボル次のシンボル)</li>
                                <li>new_low = low + range * 累積確率(シンボル)</li>
                                <li>high = new_high、low = new_low に更新</li>
                            </ul>
                        </li>
                        <li>適応型モデルを使用している場合は、シンボルごとに確率モデルを更新</li>
                    </ul>
                </li>
                <li>スケーリング（精度対策）：
                    <ul>
                        <li>low と high の最上位ビットが同じ場合、そのビットを出力し、両方の値をシフト</li>
                        <li>low が 0.25 に近づき、high が 0.75 に近づく場合（アンダーフロー状態）の特別処理</li>
                        <li>このスケーリング処理を区間が十分に広がるまで繰り返す</li>
                    </ul>
                </li>
                <li>終了処理：
                    <ul>
                        <li>入力シーケンスの終了を示す特別なシンボル（EOF）を処理するか、</li>
                        <li>最終区間を一意に特定できる数値（通常は low）を出力</li>
                        <li>残りのスケーリングビットを処理</li>
                    </ul>
                </li>
            </ol>
            
            <h4>2. デコード（復号）プロセス</h4>
            <ol>
                <li>初期設定：
                    <ul>
                        <li>エンコード時と同じ確率モデルを使用</li>
                        <li>エンコードされた数値を読み込む</li>
                        <li>区間を初期化：下限値（low）= 0.0、上限値（high）= 1.0</li>
                    </ul>
                </li>
                <li>復号処理：
                    <ul>
                        <li>エンコードされた数値がどのシンボルの区間に含まれるかを特定</li>
                        <li>特定されたシンボルを出力</li>
                        <li>エンコード時と同様に区間を更新：
                            <ul>
                                <li>range = high - low</li>
                                <li>high = low + range * 累積確率(シンボル次のシンボル)</li>
                                <li>low = low + range * 累積確率(シンボル)</li>
                            </ul>
                        </li>
                        <li>適応型モデルの場合、確率モデルを更新</li>
                    </ul>
                </li>
                <li>スケーリング（エンコードと同期）：
                    <ul>
                        <li>エンコードと同じスケーリングルールを適用</li>
                        <li>スケーリングが発生した場合、追加のビットを読み込む</li>
                    </ul>
                </li>
                <li>終了判定：
                    <ul>
                        <li>EOF シンボルを検出するか、事前に指定された長さに達するまで処理を継続</li>
                    </ul>
                </li>
            </ol>
            
            <h4>例：文字列 "ABBCABD" を確率モデル A:0.4, B:0.3, C:0.2, D:0.1 で符号化する場合</h4>
            <ol>
                <li>確率モデルから累積分布を計算：
                    <ul>
                        <li>A: [0.0, 0.4)</li>
                        <li>B: [0.4, 0.7)</li>
                        <li>C: [0.7, 0.9)</li>
                        <li>D: [0.9, 1.0)</li>
                    </ul>
                </li>
                <li>各シンボルを処理：
                    <ul>
                        <li>'A': low=0.0, high=0.4, range=0.4</li>
                        <li>'B': low=0.16(0.0+0.4*0.4), high=0.28(0.0+0.4*0.7), range=0.12</li>
                        <li>'B': low=0.208(0.16+0.12*0.4), high=0.244(0.16+0.12*0.7), range=0.036</li>
                        <li>'C': low=0.2332(0.208+0.036*0.7), high=0.2404(0.208+0.036*0.9), range=0.0072</li>
                        <li>以下同様に処理...</li>
                    </ul>
                </li>
                <li>最終的に得られる区間から、最も効率的に表現できる数値（例：0.23567）を選択して出力</li>
            </ol>
    
            <h3>計算量</h3>
            <p>算術符号化アルゴリズムの計算量は以下の通りです：</p>
            
            <h4>時間計算量</h4>
            <ul>
                <li><strong>エンコード処理</strong>:
                    <ul>
                        <li>入力シーケンス処理：O(n) - ここでnは入力シンボルの数</li>
                        <li>各シンボル処理時の確率モデル検索：O(log k) または O(1) - kはアルファベットサイズ、実装による</li>
                        <li>適応型モデルの更新：O(log k) または O(k)</li>
                    </ul>
                </li>
                <li><strong>デコード処理</strong>:
                    <ul>
                        <li>出力シンボルの検索：O(log k) または O(k) - 実装による</li>
                        <li>全体の処理：O(n × log k) または O(n × k)</li>
                    </ul>
                </li>
                <li>全体としての時間計算量は、効率的な実装では O(n × log k) または単純な実装では O(n × k)</li>
            </ul>
            
            <h4>空間計算量</h4>
            <ul>
                <li><strong>確率モデルの格納</strong>: O(k) - アルファベットサイズに比例</li>
                <li><strong>累積分布関数</strong>: O(k)</li>
                <li><strong>作業用変数</strong>: O(1) - 固定数の変数（low, high, range など）</li>
                <li><strong>出力バッファ</strong>: 最悪の場合 O(n) - 通常は圧縮により小さくなる</li>
                <li>全体としての空間計算量は O(k + 出力サイズ)</li>
            </ul>
            
            <p>算術符号化の実装において、精度の問題に対処するために、浮動小数点演算の代わりに整数演算を用いることが一般的です。この場合、処理する整数のビット数に応じて、定数倍の処理時間増加が発生することがあります。また、アンダーフロー対策のための特別な処理も必要になります。</p>
            
            <p>最適化された実装では、シンボル検索にバイナリサーチやハッシュテーブルを使用することで、O(log k)またはO(1)の時間複雑性を実現できます。特に適応型モデルでは、頻度カウントの更新や再計算が効率的に行えるデータ構造（例：フェノウィック木）を使用することが重要です。</p>
            
            <p>実用的な観点からは、算術符号化はハフマン符号化よりも計算コストが高い傾向がありますが、圧縮率の向上（特に偏りの大きな確率分布の場合）によって、その追加コストが正当化されることが多いです。また、モダンなプロセッサでは、パイプライン処理やSIMD命令を活用することで、実行速度を大幅に向上させることが可能です。</p>
        </div>
    </div>
</body>
</html>